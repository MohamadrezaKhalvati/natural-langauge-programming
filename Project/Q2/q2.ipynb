{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    "    CountVectorizer,\n",
    ")\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import itertools\n",
    "from langdetect import detect\n",
    "import langdetect\n",
    "from collections import Counter\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import reuters\n",
    "from nltk.util import bigrams\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import demoji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../Q1/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1157 entries, 0 to 1156\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   postUrl             1157 non-null   object\n",
      " 1   id                  1157 non-null   int64 \n",
      " 2   text                1156 non-null   object\n",
      " 3   ownerUsername       1157 non-null   object\n",
      " 4   ownerProfilePicUrl  1157 non-null   object\n",
      " 5   timestamp           1157 non-null   object\n",
      " 6   likesCount          1157 non-null   int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 63.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postUrl</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ownerUsername</th>\n",
       "      <th>ownerProfilePicUrl</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>17981320055390052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n4i1er</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T01:46:41.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18225095332247021</td>\n",
       "      <td>üòçüòçüî•üî•üî•</td>\n",
       "      <td>farid.zand1997</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T09:30:36.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18016249762974314</td>\n",
       "      <td>patm</td>\n",
       "      <td>andreprivet_</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T12:32:20.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>17980123316614267</td>\n",
       "      <td>@hoccein_hemati68 ÿß€åŸÜ ⁄©Ÿàÿµ⁄©ÿ¥ ÿ™Ÿà ÿß€åÿ±ÿßŸÜ ÿ®ŸàÿØ ŸÜŸáÿß€åÿ™...</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T13:14:43.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18036756691566765</td>\n",
       "      <td>@amir_niarashid üí©ü§£üñï</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T13:15:08.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    postUrl                 id  \\\n",
       "0  https://www.instagram.com/p/Cz67N84Pezn/  17981320055390052   \n",
       "1  https://www.instagram.com/p/Cz67N84Pezn/  18225095332247021   \n",
       "2  https://www.instagram.com/p/Cz67N84Pezn/  18016249762974314   \n",
       "3  https://www.instagram.com/p/Cz67N84Pezn/  17980123316614267   \n",
       "4  https://www.instagram.com/p/Cz67N84Pezn/  18036756691566765   \n",
       "\n",
       "                                                text   ownerUsername  \\\n",
       "0                                                NaN          n4i1er   \n",
       "1                                              üòçüòçüî•üî•üî•  farid.zand1997   \n",
       "2                                               patm    andreprivet_   \n",
       "3  @hoccein_hemati68 ÿß€åŸÜ ⁄©Ÿàÿµ⁄©ÿ¥ ÿ™Ÿà ÿß€åÿ±ÿßŸÜ ÿ®ŸàÿØ ŸÜŸáÿß€åÿ™...   kurd___boy666   \n",
       "4                                @amir_niarashid üí©ü§£üñï   kurd___boy666   \n",
       "\n",
       "                                  ownerProfilePicUrl  \\\n",
       "0  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "1  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "2  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "3  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "4  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "\n",
       "                  timestamp  likesCount  \n",
       "0  2023-12-09T01:46:41.000Z           0  \n",
       "1  2023-12-09T09:30:36.000Z           0  \n",
       "2  2023-12-09T12:32:20.000Z           0  \n",
       "3  2023-12-09T13:14:43.000Z           0  \n",
       "4  2023-12-09T13:15:08.000Z           0  "
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove comments with empty text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove text that is not related to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\n",
    "    data[\"text\"].apply(lambda x: all([token.pos_ != \"FOREIGN\" for token in nlp(x)]))\n",
    "    == True\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp to a standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-ASCII characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].apply(lambda x: \"\".join([ch for ch in x if ord(ch) < 128]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].str.replace(\"[^\\w\\s]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "data[\"text\"] = data[\"text\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"text\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_the_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = data[\"text\"].apply(tokenize_the_text).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = [token for entry_tokens in preprocessed_data for token in entry_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(set(total_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, n, dataset, alpha=1):\n",
    "    probabilities = [model(*dataset[i-n+1:i+1], dataset[:i], alpha) for i in range(n-1, len(dataset))]\n",
    "    perplexity = np.exp(-np.mean(np.log(probabilities)))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unigram language model is a simple yet powerful statistical model used in natural language processing (NLP) to predict the probability of occurrence of a word in a sequence of words. It assumes that the probability of a word appearing in a sentence is independent of the context in which it appears. This assumption, while not entirely accurate, often provides a reasonable approximation of the true word distribution in a language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramModel(token, dataset, alpha=1):\n",
    "    token_count = Counter(dataset)\n",
    "    return (token_count[token] + alpha) / (len(dataset) + alpha * vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigram language model is a statistical language model that predicts the probability of a word appearing in a sequence of words based on the word that precedes it. Unlike unigram models, which assume that words occur independently of each other, bigram models take into account the sequential nature of language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramModel(token1, token2, dataset, alpha=1):\n",
    "    token_count = Counter(dataset)\n",
    "    bigram_count = Counter(zip(dataset, dataset[1:]))\n",
    "    return (bigram_count[(token1, token2)] + alpha) / (token_count[token1] + alpha * vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trigram language model is a statistical language model that predicts the probability of a word appearing in a sequence of words based on the two preceding words. It takes into account the sequential nature of language by considering the dependencies between three consecutive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigramModel(token1, token2, token3, dataset, alpha=1):\n",
    "    token_count = Counter(dataset)\n",
    "    trigram_count = Counter(zip(dataset, dataset[1:], dataset[2:]))\n",
    "    bigram_count = Counter(zip(dataset, dataset[1:]))\n",
    "    return (trigram_count[(token1, token2, token3)] + alpha) / (bigram_count[(token1, token2)] + alpha * vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate perplexity base on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, n, dataset, alpha=1):\n",
    "    probabilities = [model(*dataset[i-n+1:i+1], dataset[:i], alpha) for i in range(n-1, len(dataset))]\n",
    "    perplexity = np.exp(-np.mean(np.log(probabilities)))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate sentence base on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, n, dataset, length=10):\n",
    "    sentence = []\n",
    "    for _ in range(length):\n",
    "        if n == 1:\n",
    "            next_token = random.choice(dataset)\n",
    "        else:\n",
    "            prev_tokens = sentence[-n+1:] if n > 1 else []\n",
    "            candidates = [token for token in set(dataset) if model(*(prev_tokens + [token]), dataset) > 0]\n",
    "            next_token = random.choice(candidates)\n",
    "        sentence.append(next_token)\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate sentence perplexity base on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_perplexity(model, n, sentence, dataset, alpha=1):\n",
    "    tokens = tokenize_the_text(sentence)\n",
    "    probabilities = [model(*tokens[i-n+1:i+1], dataset, alpha) for i in range(n-1, len(tokens))]\n",
    "    perplexity = np.exp(-np.mean(np.log(probabilities)))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_report(model, n, dataset, alpha=1, num_sentences=5):\n",
    "    print(f\"Generating and evaluating {num_sentences} sentences for {n}-gram model:\")\n",
    "    for i in range(num_sentences):\n",
    "        generated_sentence = generate_sentence(model, n, dataset)\n",
    "        perplexity = calculate_sentence_perplexity(model, n, generated_sentence, dataset, alpha)\n",
    "        print(f\"Generated Sentence {i+1}: {generated_sentence}\")\n",
    "        print(f\"Perplexity: {perplexity}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unigram model sentence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and evaluating 5 sentences for 1-gram model:\n",
      "Generated Sentence 1: groceries mi coming gym lplucasdiasoficial lagta done llama taking https\n",
      "Perplexity: 1791.447914483821\n",
      "\n",
      "Generated Sentence 2: first quiser natural umas para awesome creatino like saying para\n",
      "Perplexity: 1017.2669044640194\n",
      "\n",
      "Generated Sentence 3: viratkohli win saying potencial attractive grvido peitudo indian implants forc\n",
      "Perplexity: 2339.0550062222874\n",
      "\n",
      "Generated Sentence 4: kkkk pra kenniemalm place water rara vegan dont lembra compared\n",
      "Perplexity: 1335.419213049373\n",
      "\n",
      "Generated Sentence 5: pasa looking cara tenha tem goes de see una ser\n",
      "Perplexity: 830.5323327830434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_and_report(unigramModel, 1, total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigram model sentence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and evaluating 5 sentences for 2-gram model:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bigramModel() missing 1 required positional argument: 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[560], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_and_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbigramModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[557], line 4\u001b[0m, in \u001b[0;36mgenerate_and_report\u001b[1;34m(model, n, dataset, alpha, num_sentences)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating and evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sentences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sentences for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-gram model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_sentences):\n\u001b[1;32m----> 4\u001b[0m     generated_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     perplexity \u001b[38;5;241m=\u001b[39m calculate_sentence_perplexity(model, n, generated_sentence, dataset, alpha)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[540], line 8\u001b[0m, in \u001b[0;36mgenerate_sentence\u001b[1;34m(model, n, dataset, length)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     prev_tokens \u001b[38;5;241m=\u001b[39m sentence[\u001b[38;5;241m-\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m----> 8\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(dataset) \u001b[38;5;28;01mif\u001b[39;00m model(\u001b[38;5;241m*\u001b[39m(prev_tokens \u001b[38;5;241m+\u001b[39m [token]), dataset) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(candidates)\n\u001b[0;32m     10\u001b[0m sentence\u001b[38;5;241m.\u001b[39mappend(next_token)\n",
      "Cell \u001b[1;32mIn[540], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     prev_tokens \u001b[38;5;241m=\u001b[39m sentence[\u001b[38;5;241m-\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m----> 8\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(dataset) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(candidates)\n\u001b[0;32m     10\u001b[0m sentence\u001b[38;5;241m.\u001b[39mappend(next_token)\n",
      "\u001b[1;31mTypeError\u001b[0m: bigramModel() missing 1 required positional argument: 'dataset'"
     ]
    }
   ],
   "source": [
    "generate_and_report(bigramModel, 2, total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trigram model sentence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and evaluating 5 sentences for 3-gram model:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "trigramModel() missing 2 required positional arguments: 'token3' and 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[546], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_and_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrigramModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[542], line 4\u001b[0m, in \u001b[0;36mgenerate_and_report\u001b[1;34m(model, n, dataset, alpha, num_sentences)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating and evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sentences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sentences for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-gram model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_sentences):\n\u001b[1;32m----> 4\u001b[0m     generated_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     perplexity \u001b[38;5;241m=\u001b[39m calculate_sentence_perplexity(model, n, generated_sentence, dataset, alpha)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[540], line 8\u001b[0m, in \u001b[0;36mgenerate_sentence\u001b[1;34m(model, n, dataset, length)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     prev_tokens \u001b[38;5;241m=\u001b[39m sentence[\u001b[38;5;241m-\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m----> 8\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(dataset) \u001b[38;5;28;01mif\u001b[39;00m model(\u001b[38;5;241m*\u001b[39m(prev_tokens \u001b[38;5;241m+\u001b[39m [token]), dataset) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(candidates)\n\u001b[0;32m     10\u001b[0m sentence\u001b[38;5;241m.\u001b[39mappend(next_token)\n",
      "Cell \u001b[1;32mIn[540], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     prev_tokens \u001b[38;5;241m=\u001b[39m sentence[\u001b[38;5;241m-\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m----> 8\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(dataset) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(candidates)\n\u001b[0;32m     10\u001b[0m sentence\u001b[38;5;241m.\u001b[39mappend(next_token)\n",
      "\u001b[1;31mTypeError\u001b[0m: trigramModel() missing 2 required positional arguments: 'token3' and 'dataset'"
     ]
    }
   ],
   "source": [
    "# generate_and_report(trigramModel, 3, total_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
