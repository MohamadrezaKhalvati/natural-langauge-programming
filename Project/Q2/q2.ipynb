{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    "    CountVectorizer,\n",
    ")\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import itertools\n",
    "from langdetect import detect\n",
    "import langdetect\n",
    "from collections import Counter\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import reuters\n",
    "from nltk.util import bigrams\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../Q1/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1157 entries, 0 to 1156\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   postUrl             1157 non-null   object\n",
      " 1   id                  1157 non-null   int64 \n",
      " 2   text                1156 non-null   object\n",
      " 3   ownerUsername       1157 non-null   object\n",
      " 4   ownerProfilePicUrl  1157 non-null   object\n",
      " 5   timestamp           1157 non-null   object\n",
      " 6   likesCount          1157 non-null   int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 63.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postUrl</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ownerUsername</th>\n",
       "      <th>ownerProfilePicUrl</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>17981320055390052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n4i1er</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T01:46:41.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18225095332247021</td>\n",
       "      <td>üòçüòçüî•üî•üî•</td>\n",
       "      <td>farid.zand1997</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T09:30:36.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18016249762974314</td>\n",
       "      <td>patm</td>\n",
       "      <td>andreprivet_</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T12:32:20.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>17980123316614267</td>\n",
       "      <td>@hoccein_hemati68 ÿß€åŸÜ ⁄©Ÿàÿµ⁄©ÿ¥ ÿ™Ÿà ÿß€åÿ±ÿßŸÜ ÿ®ŸàÿØ ŸÜŸáÿß€åÿ™...</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T13:14:43.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18036756691566765</td>\n",
       "      <td>@amir_niarashid üí©ü§£üñï</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09T13:15:08.000Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    postUrl                 id  \\\n",
       "0  https://www.instagram.com/p/Cz67N84Pezn/  17981320055390052   \n",
       "1  https://www.instagram.com/p/Cz67N84Pezn/  18225095332247021   \n",
       "2  https://www.instagram.com/p/Cz67N84Pezn/  18016249762974314   \n",
       "3  https://www.instagram.com/p/Cz67N84Pezn/  17980123316614267   \n",
       "4  https://www.instagram.com/p/Cz67N84Pezn/  18036756691566765   \n",
       "\n",
       "                                                text   ownerUsername  \\\n",
       "0                                                NaN          n4i1er   \n",
       "1                                              üòçüòçüî•üî•üî•  farid.zand1997   \n",
       "2                                               patm    andreprivet_   \n",
       "3  @hoccein_hemati68 ÿß€åŸÜ ⁄©Ÿàÿµ⁄©ÿ¥ ÿ™Ÿà ÿß€åÿ±ÿßŸÜ ÿ®ŸàÿØ ŸÜŸáÿß€åÿ™...   kurd___boy666   \n",
       "4                                @amir_niarashid üí©ü§£üñï   kurd___boy666   \n",
       "\n",
       "                                  ownerProfilePicUrl  \\\n",
       "0  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "1  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "2  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "3  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "4  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "\n",
       "                  timestamp  likesCount  \n",
       "0  2023-12-09T01:46:41.000Z           0  \n",
       "1  2023-12-09T09:30:36.000Z           0  \n",
       "2  2023-12-09T12:32:20.000Z           0  \n",
       "3  2023-12-09T13:14:43.000Z           0  \n",
       "4  2023-12-09T13:15:08.000Z           0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove comments with empty text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove text that is not related to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\n",
    "    data[\"text\"].apply(lambda x: all([token.pos_ != \"FOREIGN\" for token in nlp(x)]))\n",
    "    == True\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp to a standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-ASCII characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].apply(lambda x: \"\".join([ch for ch in x if ord(ch) < 128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postUrl</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ownerUsername</th>\n",
       "      <th>ownerProfilePicUrl</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18225095332247021</td>\n",
       "      <td></td>\n",
       "      <td>farid.zand1997</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 09:30:36+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18016249762974314</td>\n",
       "      <td>patm</td>\n",
       "      <td>andreprivet_</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 12:32:20+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>17980123316614267</td>\n",
       "      <td>@hoccein_hemati68          !</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 13:14:43+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18036756691566765</td>\n",
       "      <td>@amir_niarashid</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 13:15:08+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18118091365334462</td>\n",
       "      <td>Nice arms</td>\n",
       "      <td>st3ph_3s0n</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 20:37:29+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    postUrl                 id  \\\n",
       "1  https://www.instagram.com/p/Cz67N84Pezn/  18225095332247021   \n",
       "2  https://www.instagram.com/p/Cz67N84Pezn/  18016249762974314   \n",
       "3  https://www.instagram.com/p/Cz67N84Pezn/  17980123316614267   \n",
       "4  https://www.instagram.com/p/Cz67N84Pezn/  18036756691566765   \n",
       "5  https://www.instagram.com/p/Cz67N84Pezn/  18118091365334462   \n",
       "\n",
       "                           text   ownerUsername  \\\n",
       "1                                farid.zand1997   \n",
       "2                          patm    andreprivet_   \n",
       "3  @hoccein_hemati68          !   kurd___boy666   \n",
       "4              @amir_niarashid    kurd___boy666   \n",
       "5                    Nice arms       st3ph_3s0n   \n",
       "\n",
       "                                  ownerProfilePicUrl  \\\n",
       "1  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "2  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "3  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "4  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "5  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "\n",
       "                  timestamp  likesCount  \n",
       "1 2023-12-09 09:30:36+00:00           0  \n",
       "2 2023-12-09 12:32:20+00:00           0  \n",
       "3 2023-12-09 13:14:43+00:00           0  \n",
       "4 2023-12-09 13:15:08+00:00           0  \n",
       "5 2023-12-09 20:37:29+00:00           0  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].str.replace(\"[^\\w\\s]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "data[\"text\"] = data[\"text\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"text\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postUrl</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ownerUsername</th>\n",
       "      <th>ownerProfilePicUrl</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18016249762974314</td>\n",
       "      <td>patm</td>\n",
       "      <td>andreprivet_</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 12:32:20+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>17980123316614267</td>\n",
       "      <td>@hoccein_hemati68 !</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 13:14:43+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18036756691566765</td>\n",
       "      <td>@amir_niarashid</td>\n",
       "      <td>kurd___boy666</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 13:15:08+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18118091365334462</td>\n",
       "      <td>nice arms</td>\n",
       "      <td>st3ph_3s0n</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-09 20:37:29+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.instagram.com/p/Cz67N84Pezn/</td>\n",
       "      <td>18247697080171707</td>\n",
       "      <td>gostoso</td>\n",
       "      <td>pedr0_hgc</td>\n",
       "      <td>https://scontent-dub4-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>2023-12-10 01:28:48+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    postUrl                 id  \\\n",
       "2  https://www.instagram.com/p/Cz67N84Pezn/  18016249762974314   \n",
       "3  https://www.instagram.com/p/Cz67N84Pezn/  17980123316614267   \n",
       "4  https://www.instagram.com/p/Cz67N84Pezn/  18036756691566765   \n",
       "5  https://www.instagram.com/p/Cz67N84Pezn/  18118091365334462   \n",
       "7  https://www.instagram.com/p/Cz67N84Pezn/  18247697080171707   \n",
       "\n",
       "                  text  ownerUsername  \\\n",
       "2                 patm   andreprivet_   \n",
       "3  @hoccein_hemati68 !  kurd___boy666   \n",
       "4      @amir_niarashid  kurd___boy666   \n",
       "5            nice arms     st3ph_3s0n   \n",
       "7              gostoso      pedr0_hgc   \n",
       "\n",
       "                                  ownerProfilePicUrl  \\\n",
       "2  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "3  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "4  https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "5  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "7  https://scontent-dub4-1.cdninstagram.com/v/t51...   \n",
       "\n",
       "                  timestamp  likesCount  \n",
       "2 2023-12-09 12:32:20+00:00           0  \n",
       "3 2023-12-09 13:14:43+00:00           0  \n",
       "4 2023-12-09 13:15:08+00:00           0  \n",
       "5 2023-12-09 20:37:29+00:00           0  \n",
       "7 2023-12-10 01:28:48+00:00           0  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(probabilities):\n",
    "    if not isinstance(probabilities, list):\n",
    "        raise TypeError(\"Input must be a list of probabilities.\")\n",
    "\n",
    "    if not probabilities:\n",
    "        raise ValueError(\"The list of probabilities is empty.\")\n",
    "\n",
    "    if not all(0 <= prob <= 1 for prob in probabilities):\n",
    "        raise ValueError(\"All probabilities must be in the range [0, 1].\")\n",
    "\n",
    "    N = len(probabilities)\n",
    "    log_prob_sum = sum(math.log2(prob) for prob in probabilities if prob > 0)\n",
    "\n",
    "    if log_prob_sum == 0:\n",
    "        raise ValueError(\n",
    "            \"All probabilities are zero, resulting in infinite perplexity.\"\n",
    "        )\n",
    "\n",
    "    perplexity = 2 ** (-1 / N * log_prob_sum)\n",
    "\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unigram language model is a simple yet powerful statistical model used in natural language processing (NLP) to predict the probability of occurrence of a word in a sequence of words. It assumes that the probability of a word appearing in a sentence is independent of the context in which it appears. This assumption, while not entirely accurate, often provides a reasonable approximation of the true word distribution in a language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramLanguageModel:\n",
    "    def __init__(self, training_corpus, smoothing_factor=0.1):\n",
    "        self.smoothing_factor = smoothing_factor\n",
    "        self.word_counts = Counter(training_corpus)\n",
    "        self.total_words = len(training_corpus)\n",
    "        self.vocabulary_size = len(set(training_corpus))\n",
    "\n",
    "    def calculate_probability(self, word):\n",
    "        # Add smoothing to handle unseen words\n",
    "        smoothed_probability = (self.word_counts[word] + self.smoothing_factor) / (self.total_words + self.smoothing_factor * self.vocabulary_size)\n",
    "        return smoothed_probability\n",
    "\n",
    "    def generate_sentence_with_probability(self, length=5):\n",
    "        sentence = [random.choices(list(self.word_counts.keys()), weights=[self.calculate_probability(word) for word in self.word_counts.keys()])[0] for _ in range(length)]\n",
    "        return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model = UnigramLanguageModel(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: lazy fox fox brown dog dog the lazy\n",
      "Generated Sentence: quick brown jumps fox quick fox dog fox\n",
      "Generated Sentence: over brown lazy brown fox jumps fox brown\n",
      "Generated Sentence: quick the fox fox brown jumps quick over\n",
      "Generated Sentence: lazy jumps the jumps over jumps brown quick\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, length=5):\n",
    "    sentence = []\n",
    "    for _ in range(length):\n",
    "        # Sample a word based on its probability\n",
    "        sampled_word = random.choices(list(model.word_counts.keys()), weights=[model.calculate_probability(word) for word in model.word_counts.keys()])[0]\n",
    "        sentence.append(sampled_word)\n",
    "    return sentence\n",
    "\n",
    "# Generate 5 sentences\n",
    "for i in range(5):\n",
    "    generated_sentence = unigram_model.generate_sentence_with_probability(length=8)\n",
    "    print(f\"Generated Sentence: {' '.join(generated_sentence)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigram language model is a statistical language model that predicts the probability of a word appearing in a sequence of words based on the word that precedes it. Unlike unigram models, which assume that words occur independently of each other, bigram models take into account the sequential nature of language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\".join(training_data)\n",
    "tokens = word_tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams = list(bigrams(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate bigram frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_freq = FreqDist(bi_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add smoothing (Laplace smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "vocab_size = len(set(tokens))\n",
    "prob_dist = LidstoneProbDist(bigram_freq, alpha, bins=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language model with bigram smoothing.\n",
      "Language model with bigram smoothing.\n",
      "Language model with bigram smoothing.\n",
      "Language model with bigram smoothing.\n",
      "Language model with bigram smoothing.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_bigram_model(corpus):\n",
    "    bigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "    unigram_counts = defaultdict(int)\n",
    "\n",
    "    # Count occurrences of unigrams and bigrams\n",
    "    for sentence in corpus:\n",
    "        tokens = sentence.split()\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigram_counts[tokens[i]][tokens[i+1]] += 1\n",
    "            unigram_counts[tokens[i]] += 1\n",
    "\n",
    "    return bigram_counts, unigram_counts\n",
    "\n",
    "def generate_sentence(bigram_model, start_token, max_length=10):\n",
    "    sentence = [start_token]\n",
    "    current_token = start_token\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        next_tokens = list(bigram_model[current_token].keys())\n",
    "        if not next_tokens:\n",
    "            break\n",
    "\n",
    "        probabilities = [bigram_model[current_token][token] / (unigram_counts[current_token] + len(bigram_model[current_token]))\n",
    "                         for token in next_tokens]\n",
    "        next_token = random.choices(next_tokens, weights=probabilities, k=1)[0]\n",
    "\n",
    "        sentence.append(next_token)\n",
    "        current_token = next_token\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example usage\n",
    "corpus = [\n",
    "    \"This is a sample sentence.\",\n",
    "    \"Sample sentence for language model.\",\n",
    "    \"Language model with bigram smoothing.\",\n",
    "    \"Smoothing helps handle unseen bigrams.\",\n",
    "    \"Bigrams and smoothing in natural language processing.\"\n",
    "]\n",
    "\n",
    "bigram_model, unigram_counts = train_bigram_model(corpus)\n",
    "\n",
    "# Generate 5 sentences\n",
    "for _ in range(5):\n",
    "    generated_sentence = generate_sentence(bigram_model, \"Language\")\n",
    "    print(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = random.choice(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ProbDistI.generate() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[237], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generated_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_word\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[231], line 10\u001b[0m, in \u001b[0;36mgenerate_sentence\u001b[1;34m(seed_word, num_sentences, max_sentence_length)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_sentence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m         next_word \u001b[38;5;241m=\u001b[39m \u001b[43mprob_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_word\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         sentence\u001b[38;5;241m.\u001b[39mappend(next_word)\n\u001b[0;32m     12\u001b[0m         current_word \u001b[38;5;241m=\u001b[39m next_word\n",
      "\u001b[1;31mTypeError\u001b[0m: ProbDistI.generate() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "generated_sentences = generate_sentence(seed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the generated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: thequickbrownfoxjumpsoverthelazydog\n",
      "Sentence 2: thequickbrownfoxjumpsoverthelazydog\n",
      "Sentence 3: thequickbrownfoxjumpsoverthelazydog\n",
      "Sentence 4: thequickbrownfoxjumpsoverthelazydog\n",
      "Sentence 5: thequickbrownfoxjumpsoverthelazydog\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(generated_sentences, start=1):\n",
    "    print(f\"Sentence {i}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trigram language model is a statistical language model that predicts the probability of a word appearing in a sequence of words based on the two preceding words. It takes into account the sequential nature of language by considering the dependencies between three consecutive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CountVectorizer for trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature names (trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the counts for each trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame to display the trigram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_df = pd.DataFrame({\"Trigram\": feature_names, \"Count\": trigram_counts.A1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame by trigram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_df = trigram_df.sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigram</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>se quiser sim</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>quiser sim mano</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>lembra muito meu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>pensou em competir</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>lembra meu comeo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>que los anabolicos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>cabeza de bolo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>work people use</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>activates hormone destroys</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>told would work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Trigram  Count\n",
       "2092               se quiser sim     13\n",
       "1988             quiser sim mano     11\n",
       "1321            lembra muito meu      3\n",
       "1769          pensou em competir      3\n",
       "1320            lembra meu comeo      3\n",
       "1945          que los anabolicos      2\n",
       "307               cabeza de bolo      2\n",
       "2611             work people use      2\n",
       "62    activates hormone destroys      2\n",
       "2367             told would work      2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigram smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CountVectorizer for trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature names (trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the counts for each trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add-one (Laplace) smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trigrams = len(feature_names)\n",
    "smoothed_counts = trigram_counts + 1\n",
    "total_tokens = smoothed_counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate smoothed probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_probabilities = smoothed_counts / total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame to display the smoothed trigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_trigram_model = pd.DataFrame(\n",
    "    {\n",
    "        \"Trigram\": feature_names,\n",
    "        \"Count\": smoothed_counts.A1,\n",
    "        \"Probability\": smoothed_probabilities.A1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame by trigram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_trigram_model = smoothed_trigram_model.sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the top trigrams with smoothed probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigram</th>\n",
       "      <th>Count</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>se quiser sim</td>\n",
       "      <td>14</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>quiser sim mano</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>lembra muito meu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>pensou em competir</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>lembra meu comeo</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>que los anabolicos</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>cabeza de bolo</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>work people use</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>activates hormone destroys</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>told would work</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Trigram  Count  Probability\n",
       "2092               se quiser sim     14     0.002581\n",
       "1988             quiser sim mano     12     0.002212\n",
       "1321            lembra muito meu      4     0.000737\n",
       "1769          pensou em competir      4     0.000737\n",
       "1320            lembra meu comeo      4     0.000737\n",
       "1945          que los anabolicos      3     0.000553\n",
       "307               cabeza de bolo      3     0.000553\n",
       "2611             work people use      3     0.000553\n",
       "62    activates hormone destroys      3     0.000553\n",
       "2367             told would work      3     0.000553"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_trigram_model.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
